{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Identifiant arc            Libelle Date et heure de comptage  \\\n",
      "6712             4264  AV_Champs_Elysees       2019-11-01 04:00:00   \n",
      "6713             4264  AV_Champs_Elysees       2019-11-01 05:00:00   \n",
      "6714             4264  AV_Champs_Elysees       2019-11-01 06:00:00   \n",
      "2607             4264  AV_Champs_Elysees       2019-11-01 07:00:00   \n",
      "2608             4264  AV_Champs_Elysees       2019-11-01 08:00:00   \n",
      "\n",
      "      Débit horaire  Taux d'occupation Etat trafic  Identifiant noeud amont  \\\n",
      "6712          746.0           10.98889      Fluide                     2294   \n",
      "6713          549.0            7.40722      Fluide                     2294   \n",
      "6714          503.0            7.66667      Fluide                     2294   \n",
      "2607          500.0            4.75500      Fluide                     2294   \n",
      "2608          525.0            5.37389      Fluide                     2294   \n",
      "\n",
      "               Libelle noeud amont  Identifiant noeud aval  \\\n",
      "6712  Av_Champs_Elysees-Washington                    2293   \n",
      "6713  Av_Champs_Elysees-Washington                    2293   \n",
      "6714  Av_Champs_Elysees-Washington                    2293   \n",
      "2607  Av_Champs_Elysees-Washington                    2293   \n",
      "2608  Av_Champs_Elysees-Washington                    2293   \n",
      "\n",
      "           Libelle noeud aval  Etat arc Date debut dispo data  \\\n",
      "6712  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "6713  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "6714  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "2607  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "2608  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "\n",
      "     Date fin dispo data                 geo_point_2d  \\\n",
      "6712          2019-06-01  48.8715358799,2.30172279246   \n",
      "6713          2019-06-01  48.8715358799,2.30172279246   \n",
      "6714          2019-06-01  48.8715358799,2.30172279246   \n",
      "2607          2019-06-01  48.8715358799,2.30172279246   \n",
      "2608          2019-06-01  48.8715358799,2.30172279246   \n",
      "\n",
      "                                              geo_shape  \n",
      "6712  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "6713  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "6714  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "2607  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "2608  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "      Identifiant arc    Libelle Date et heure de comptage  Débit horaire  \\\n",
      "3186              191  Sts_Peres       2019-11-01 04:00:00          259.0   \n",
      "2892              191  Sts_Peres       2019-11-01 05:00:00          197.0   \n",
      "2893              191  Sts_Peres       2019-11-01 06:00:00          163.0   \n",
      "2894              191  Sts_Peres       2019-11-01 07:00:00          170.0   \n",
      "2895              191  Sts_Peres       2019-11-01 08:00:00          225.0   \n",
      "\n",
      "      Taux d'occupation Etat trafic  Identifiant noeud amont  \\\n",
      "3186            3.00611      Fluide                      114   \n",
      "2892            2.50778      Fluide                      114   \n",
      "2893            2.05111      Fluide                      114   \n",
      "2894            2.08944      Fluide                      114   \n",
      "2895            2.91500      Fluide                      114   \n",
      "\n",
      "     Libelle noeud amont  Identifiant noeud aval    Libelle noeud aval  \\\n",
      "3186  Sts_Peres-Voltaire                     119  Sts_Peres-Universite   \n",
      "2892  Sts_Peres-Voltaire                     119  Sts_Peres-Universite   \n",
      "2893  Sts_Peres-Voltaire                     119  Sts_Peres-Universite   \n",
      "2894  Sts_Peres-Voltaire                     119  Sts_Peres-Universite   \n",
      "2895  Sts_Peres-Voltaire                     119  Sts_Peres-Universite   \n",
      "\n",
      "      Etat arc Date debut dispo data Date fin dispo data  \\\n",
      "3186  Invalide            2005-01-01          2019-06-01   \n",
      "2892  Invalide            2005-01-01          2019-06-01   \n",
      "2893  Invalide            2005-01-01          2019-06-01   \n",
      "2894  Invalide            2005-01-01          2019-06-01   \n",
      "2895  Invalide            2005-01-01          2019-06-01   \n",
      "\n",
      "                     geo_point_2d  \\\n",
      "3186  48.8572803712,2.33245419072   \n",
      "2892  48.8572803712,2.33245419072   \n",
      "2893  48.8572803712,2.33245419072   \n",
      "2894  48.8572803712,2.33245419072   \n",
      "2895  48.8572803712,2.33245419072   \n",
      "\n",
      "                                              geo_shape  \n",
      "3186  {\"type\": \"LineString\", \"coordinates\": [[2.3332...  \n",
      "2892  {\"type\": \"LineString\", \"coordinates\": [[2.3332...  \n",
      "2893  {\"type\": \"LineString\", \"coordinates\": [[2.3332...  \n",
      "2894  {\"type\": \"LineString\", \"coordinates\": [[2.3332...  \n",
      "2895  {\"type\": \"LineString\", \"coordinates\": [[2.3332...  \n",
      "      Identifiant arc     Libelle Date et heure de comptage  Débit horaire  \\\n",
      "5967             5671  Convention       2019-11-01 04:00:00          323.0   \n",
      "5968             5671  Convention       2019-11-01 05:00:00          272.0   \n",
      "813              5671  Convention       2019-11-01 06:00:00          240.0   \n",
      "814              5671  Convention       2019-11-01 07:00:00          216.0   \n",
      "815              5671  Convention       2019-11-01 08:00:00          260.0   \n",
      "\n",
      "      Taux d'occupation Etat trafic  Identifiant noeud amont  \\\n",
      "5967            1.67722      Fluide                     2937   \n",
      "5968            1.41056      Fluide                     2937   \n",
      "813             1.35667      Fluide                     2937   \n",
      "814             1.14056      Fluide                     2937   \n",
      "815             1.85722      Fluide                     2937   \n",
      "\n",
      "      Libelle noeud amont  Identifiant noeud aval Libelle noeud aval  \\\n",
      "5967  Lecourbe-Convention                    2973  Convention-Blomet   \n",
      "5968  Lecourbe-Convention                    2973  Convention-Blomet   \n",
      "813   Lecourbe-Convention                    2973  Convention-Blomet   \n",
      "814   Lecourbe-Convention                    2973  Convention-Blomet   \n",
      "815   Lecourbe-Convention                    2973  Convention-Blomet   \n",
      "\n",
      "      Etat arc Date debut dispo data Date fin dispo data  \\\n",
      "5967  Invalide            2005-01-01          2019-06-01   \n",
      "5968  Invalide            2005-01-01          2019-06-01   \n",
      "813   Invalide            2005-01-01          2019-06-01   \n",
      "814   Invalide            2005-01-01          2019-06-01   \n",
      "815   Invalide            2005-01-01          2019-06-01   \n",
      "\n",
      "                     geo_point_2d  \\\n",
      "5967  48.8386343727,2.29320560272   \n",
      "5968  48.8386343727,2.29320560272   \n",
      "813   48.8386343727,2.29320560272   \n",
      "814   48.8386343727,2.29320560272   \n",
      "815   48.8386343727,2.29320560272   \n",
      "\n",
      "                                              geo_shape  \n",
      "5967  {\"type\": \"LineString\", \"coordinates\": [[2.2918...  \n",
      "5968  {\"type\": \"LineString\", \"coordinates\": [[2.2918...  \n",
      "813   {\"type\": \"LineString\", \"coordinates\": [[2.2918...  \n",
      "814   {\"type\": \"LineString\", \"coordinates\": [[2.2918...  \n",
      "815   {\"type\": \"LineString\", \"coordinates\": [[2.2918...  \n",
      "Int64Index([6712, 6713, 6714, 2607, 2608, 6715, 6716, 2609, 2610, 2611,\n",
      "            ...\n",
      "              53,   51,  106,  152,  145,   10,  151,   90,   50,  146],\n",
      "           dtype='int64', length=28409)\n",
      "      Identifiant arc            Libelle Date et heure de comptage  \\\n",
      "6712             4264  AV_Champs_Elysees       2019-11-01 04:00:00   \n",
      "6713             4264  AV_Champs_Elysees       2019-11-01 05:00:00   \n",
      "6714             4264  AV_Champs_Elysees       2019-11-01 06:00:00   \n",
      "2607             4264  AV_Champs_Elysees       2019-11-01 07:00:00   \n",
      "2608             4264  AV_Champs_Elysees       2019-11-01 08:00:00   \n",
      "\n",
      "      Débit horaire  Taux d'occupation Etat trafic  Identifiant noeud amont  \\\n",
      "6712          746.0           10.98889      Fluide                     2294   \n",
      "6713          549.0            7.40722      Fluide                     2294   \n",
      "6714          503.0            7.66667      Fluide                     2294   \n",
      "2607          500.0            4.75500      Fluide                     2294   \n",
      "2608          525.0            5.37389      Fluide                     2294   \n",
      "\n",
      "               Libelle noeud amont  Identifiant noeud aval  \\\n",
      "6712  Av_Champs_Elysees-Washington                    2293   \n",
      "6713  Av_Champs_Elysees-Washington                    2293   \n",
      "6714  Av_Champs_Elysees-Washington                    2293   \n",
      "2607  Av_Champs_Elysees-Washington                    2293   \n",
      "2608  Av_Champs_Elysees-Washington                    2293   \n",
      "\n",
      "           Libelle noeud aval  Etat arc Date debut dispo data  \\\n",
      "6712  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "6713  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "6714  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "2607  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "2608  Av_Champs_Elysees-Berri  Invalide            2005-01-01   \n",
      "\n",
      "     Date fin dispo data                 geo_point_2d  \\\n",
      "6712          2019-06-01  48.8715358799,2.30172279246   \n",
      "6713          2019-06-01  48.8715358799,2.30172279246   \n",
      "6714          2019-06-01  48.8715358799,2.30172279246   \n",
      "2607          2019-06-01  48.8715358799,2.30172279246   \n",
      "2608          2019-06-01  48.8715358799,2.30172279246   \n",
      "\n",
      "                                              geo_shape  \n",
      "6712  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "6713  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "6714  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "2607  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n",
      "2608  {\"type\": \"LineString\", \"coordinates\": [[2.3009...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "#Nous ouvrons le dataset\n",
    "df_ACE = pd.read_csv(os.path.join(r\"comptages-routiers-permanents_ACE.csv\"), sep=\";\")\n",
    "df_Sts = pd.read_csv(os.path.join(r\"comptages-routiers-permanents_Sts.csv\"), sep=\";\")\n",
    "df_convention = pd.read_csv(os.path.join(r\"comptages-routiers-permanents_convention.csv\"), sep=\";\")\n",
    "\n",
    "\n",
    "#print(df_ACE.head())\n",
    "\n",
    "(df_ACE, df_Sts, df_convention)\n",
    "tagg = [\"Champs Elysées\", \"Sts-Pères\", \"Convention\"]\n",
    "\n",
    "def clean_date(date):\n",
    "    \n",
    "    date = re.sub('T', ' ', date)\n",
    "    date=date[:-6]\n",
    "    return date\n",
    "\n",
    "#compte_1=df_ACE.groupby(\"Etat arc\")[\"Date et heure de comptage\"].nunique()\n",
    "for df in (df_ACE, df_Sts, df_convention):\n",
    "    df['Date et heure de comptage'] = df['Date et heure de comptage'].apply(lambda s : clean_date(s))\n",
    "\n",
    "#df_convention['Date et heure de comptage'] = df_convention['Date et heure de comptage'].apply(lambda s : clean_date(s))\n",
    "#df_Sts['Date et heure de comptage'] = df_Sts['Date et heure de comptage'].apply(lambda s : clean_date(s))\n",
    "\n",
    "#Nous adaptons notre features \"Date\" au format d'une série temporelle\n",
    "\n",
    "for df in (df_ACE, df_Sts, df_convention):\n",
    "    df['Date et heure de comptage']= pd.to_datetime(df[\"Date et heure de comptage\"], format='%Y-%m-%d %H:%M:%S')\n",
    " \n",
    "    \n",
    "for df in (df_ACE, df_Sts, df_convention):\n",
    "    df.sort_values(\"Date et heure de comptage\",inplace = True)\n",
    "    print(df.head())\n",
    "\n",
    "df_rues = pd.concat([df_ACE, df_Sts, df_convention])\n",
    "#Nous indiquons que la série temporelle est indexée selon la date\n",
    "\n",
    "\n",
    "#df_rues = df_ACE.set_index('Date et heure de comptage')\n",
    "\n",
    "    \n",
    "print(df_rues.index)\n",
    "\n",
    "#Nous créons plusieurs colonnes permettant de situer la donnée par jour/mois/année. Cela nous servira pa la suite pour traiter\n",
    "#la données selon différentes échelles temporelles.\n",
    "\n",
    "\n",
    "#df_rues['Year'] = df_rues.index.year\n",
    "#df_rues['Month'] = df_rues.index.month\n",
    "#df_rues['Weekday Name'] = df_rues.index.weekday\n",
    "#df_rues['Hour'] = df_rues.index.hour\n",
    "\n",
    "\n",
    "\n",
    "print(df_rues.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Identifiant arc Date et heure de comptage  Débit horaire  \\\n",
      "6712             4264       2019-11-01 04:00:00          746.0   \n",
      "6713             4264       2019-11-01 05:00:00          549.0   \n",
      "6714             4264       2019-11-01 06:00:00          503.0   \n",
      "2607             4264       2019-11-01 07:00:00          500.0   \n",
      "2608             4264       2019-11-01 08:00:00          525.0   \n",
      "\n",
      "      Taux d'occupation Etat trafic  Etat arc Date fin dispo data  \n",
      "6712           10.98889      Fluide  Invalide          2019-06-01  \n",
      "6713            7.40722      Fluide  Invalide          2019-06-01  \n",
      "6714            7.66667      Fluide  Invalide          2019-06-01  \n",
      "2607            4.75500      Fluide  Invalide          2019-06-01  \n",
      "2608            5.37389      Fluide  Invalide          2019-06-01  \n",
      "                 Date et heure de comptage  Débit horaire  Taux d'occupation  \\\n",
      "Identifiant arc                                                                \n",
      "191                                   9478           1045               7721   \n",
      "4264                                  9452           1460               8595   \n",
      "5671                                  9479           1180               7603   \n",
      "\n",
      "                 Etat trafic  Etat arc  Date fin dispo data  \n",
      "Identifiant arc                                              \n",
      "191                        4         2                    1  \n",
      "4264                       5         2                    1  \n",
      "5671                       5         2                    1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_rues.drop(columns=[\"Libelle noeud aval\", \"Libelle noeud amont\", \"Libelle\", \"Identifiant noeud aval\", \"Identifiant noeud amont\", \"geo_point_2d\", \"geo_shape\", \"Date debut dispo data\", \"Date debut dispo data\"], inplace = True)\n",
    "print(df_rues.head())\n",
    "compte_1=df_rues.groupby(\"Identifiant arc\").nunique()\n",
    "print(compte_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, size, step):\n",
    "    \"\"\" Yield successive n-sized chunks from l.\n",
    "    \"\"\"\n",
    "    l = l[:(len(l) // size) * size]\n",
    "    return [x for x in [l[i : i + size] for i in range(0, len(l), step)] if len(x) == size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rues\n",
    "\n",
    "df = df.replace({4264:\"1\", 5671: \"2\", 191:\"3\"})\n",
    "df[\"Identifiant arc\"]=df[\"Identifiant arc\"].astype(str)\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramètres\n",
    "N_input = 7*24\n",
    "N_output = 1*24\n",
    "device = 'cuda'\n",
    "p_test = 0.2\n",
    "optimizer_parameters = {'lr': 0.001}\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Identifiant arc, Date et heure de comptage, Débit horaire, Taux d'occupation, Etat trafic, Etat arc, Date fin dispo data]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Nous précisons ici que la série temporelle possède une fréquence à l'heure et nous remplaçons les valeurs manquantes par\n",
    "#la valeur qui les précèdent.\n",
    "\n",
    "missing_df_1= df[df.isnull().any(1)]\n",
    "print(missing_df_1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ml_mvp_1\\lib\\site-packages\\ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#df_meta = df[\"Service\"]\n",
    "#df_meta['Service'] = df_meta.index.astype(str)\n",
    "#df_meta.astype(pd.CategoricalDtype(categories=df_meta.index)).cat.codes\n",
    "#print(df_meta.head())\n",
    "df[\"Débit horaire\"]= df[\"Débit horaire\"].astype(int)\n",
    "data = df.sort_values(['Date et heure de comptage', 'Identifiant arc']).groupby('Identifiant arc')[\"Débit horaire\"].apply(lambda x: chunks(x.values, size=N_input+N_output, step=N_output))\n",
    "#print(data.head())\n",
    "\n",
    "#print(data.values)\n",
    "data_numpy = np.array([np.array(x) for x in data.values])\n",
    "\n",
    "print(data_numpy.dtype)\n",
    "dep = np.array([x for x in data.index])\n",
    "#print(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mélange les services\n",
    "ind = np.arange(len(data_numpy))\n",
    "np.random.shuffle(ind)\n",
    "data_numpy = data_numpy[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sépare en train/test\n",
    "nb_train = int(len(data_numpy)*(1-p_test))\n",
    "\n",
    "data_numpy_test = data_numpy[nb_train:]\n",
    "data_numpy_train = data_numpy[:nb_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatène chaque départements ensembles\n",
    "data_numpy_train = np.concatenate(data_numpy_train)\n",
    "data_numpy_test = np.concatenate(data_numpy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[746 549 503 ... 879 745 541]\n",
      " [466 393 434 ... 798 682 574]\n",
      " [679 463 488 ... 727 625 445]\n",
      " ...\n",
      " [296 273 229 ... 359 410 443]\n",
      " [276 221 182 ... 594 568 557]\n",
      " [462 391 279 ... 659 668 679]]\n",
      "[[ 0.50706914 -0.00186829 -0.12070647 ...  0.85066649  0.5044857\n",
      "  -0.0225358 ]\n",
      " [-0.2162937  -0.40488473 -0.29896374 ...  0.64140795  0.34172906\n",
      "   0.06271768]\n",
      " [ 0.33397874 -0.22404402 -0.15945805 ...  0.4579838   0.19447305\n",
      "  -0.27054592]\n",
      " ...\n",
      " [-0.65547828 -0.71489737 -0.82856868 ... -0.49272165 -0.36096627\n",
      "  -0.27571279]\n",
      " [-0.70714706 -0.84923619 -0.9499903  ...  0.11438645  0.04721705\n",
      "   0.01879922]\n",
      " [-0.22662746 -0.41005161 -0.69939674 ...  0.28230997  0.30556092\n",
      "   0.33397874]]\n"
     ]
    }
   ],
   "source": [
    "# Normalise par mean-std calculées sur le data de train\n",
    "print(data_numpy_train)\n",
    "std = data_numpy_train.std((0,1))[None]\n",
    "mean = data_numpy_train.mean((0,1))[None]\n",
    "data_numpy_train = (data_numpy_train-mean[None])/std[None]\n",
    "data_numpy_test = (data_numpy_test-mean[None])/std[None]\n",
    "print(data_numpy_train)\n",
    "def rescale(data):\n",
    "    return data * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50706914 -0.00186829 -0.12070647 ...  0.29522716  0.01879922\n",
      "  -0.51080572]\n",
      " [-0.2162937  -0.40488473 -0.29896374 ...  0.85066649  0.5044857\n",
      "  -0.0225358 ]\n",
      " [ 0.33397874 -0.22404402 -0.15945805 ...  0.64140795  0.34172906\n",
      "   0.06271768]\n",
      " ...\n",
      " [-0.65547828 -0.71489737 -0.82856868 ... -0.04578675 -0.05870394\n",
      "  -0.14137398]\n",
      " [-0.70714706 -0.84923619 -0.9499903  ... -0.49272165 -0.36096627\n",
      "  -0.27571279]\n",
      " [-0.22662746 -0.41005161 -0.69939674 ...  0.11438645  0.04721705\n",
      "   0.01879922]]\n"
     ]
    }
   ],
   "source": [
    "# Sépare en input/output\n",
    "X_train, y_train = data_numpy_train[:, :N_input], data_numpy_train[:, N_input:]\n",
    "X_test, y_test = data_numpy_test[:, :N_input], data_numpy_test[:, N_input:]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "object\n",
      "tensor([[ 0.5071, -0.0019, -0.1207,  ...,  0.2952,  0.0188, -0.5108],\n",
      "        [-0.2163, -0.4049, -0.2990,  ...,  0.8507,  0.5045, -0.0225],\n",
      "        [ 0.3340, -0.2240, -0.1595,  ...,  0.6414,  0.3417,  0.0627],\n",
      "        ...,\n",
      "        [-0.6555, -0.7149, -0.8286,  ..., -0.0458, -0.0587, -0.1414],\n",
      "        [-0.7071, -0.8492, -0.9500,  ..., -0.4927, -0.3610, -0.2757],\n",
      "        [-0.2266, -0.4101, -0.6994,  ...,  0.1144,  0.0472,  0.0188]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "\n",
    "#import torch\n",
    "print(type(X_train))\n",
    "print(data_numpy.dtype)\n",
    "print(torch.from_numpy(X_train))\n",
    "dataset_train = torch.utils.data.TensorDataset(torch.FloatTensor(X_train[:,:,None]),\n",
    "                                               torch.FloatTensor(y_train[:,:,None]))\n",
    "dataset_test = torch.utils.data.TensorDataset(torch.FloatTensor(X_test[:,:,None]),\n",
    "                                              torch.FloatTensor(y_test[:,:,None]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw, dtw_path\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "def fake_baye(outputs, log_sigmas, target):\n",
    "    loss = 1/2 * (log_sigmas + torch.exp(-log_sigmas) * (outputs - target)**2)\n",
    "    return loss.mean()\n",
    "\n",
    "def loss_rescale_factor(log_rescale_factor, outputs, log_sigmas, target):\n",
    "    batch_size = outputs.shape[0]\n",
    "    loss = 1/2 * torch.exp(-2 * log_rescale_factor) * torch.sum(torch.exp(-log_sigmas) * (outputs - target)**2)\n",
    "    loss += batch_size * log_rescale_factor\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train_model(net, loss_type, optimizer_parameters, epochs=1000, gamma=0.001,\n",
    "                eval_every=50, Lambda=1, alpha=0.5, beta=0.):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), **optimizer_parameters)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    if hasattr(net, 'log_rescale_factor'):\n",
    "        optimizer_rescale_factor = torch.optim.Adam([net.log_rescale_factor], **optimizer_parameters)\n",
    "\n",
    "    t = tqdm.notebook.tqdm(range(epochs))\n",
    "    for epoch in t:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            net.train()\n",
    "            if hasattr(net, 'log_rescale_factor'):\n",
    "                net.log_rescale_factor.require_grad = False\n",
    "\n",
    "            inputs, target = data\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            batch_size, N_output = target.shape[0:2]\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            if len(outputs) == 2:\n",
    "                outputs, _ = outputs\n",
    "            else:\n",
    "                outputs, log_sigmas, _ = outputs\n",
    "\n",
    "            loss_mse, loss_shape, loss_temporal = torch.tensor(\n",
    "                0), torch.tensor(0), torch.tensor(0)\n",
    "\n",
    "            loss = 0\n",
    "            if 'mse' in loss_type:\n",
    "                loss_mse = 100 * criterion(outputs, target)\n",
    "                loss += loss_mse\n",
    "\n",
    "            if 'dilate' in loss_type:\n",
    "                loss_dilate, loss_shape, loss_temporal = dilate_loss(\n",
    "                    outputs, target, alpha, gamma, device)\n",
    "                loss += loss_dilate\n",
    "\n",
    "            if 'fake_baye' in loss_type:\n",
    "                loss_fake_baye = fake_baye(outputs, log_sigmas, target)\n",
    "                loss += loss_fake_baye\n",
    "\n",
    "            if 'all_target_regression' in loss_type:\n",
    "                loss_target_week_regression = F.mse_loss(outputs.sum(1), target.sum(1))\n",
    "                loss += loss_target_week_regression\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if hasattr(net, 'log_rescale_factor'):\n",
    "                net.log_rescale_factor.require_grad = True\n",
    "\n",
    "                loss_rescale = loss_rescale_factor(net.log_rescale_factor, outputs.detach(), log_sigmas.detach(),\n",
    "                                                   target)\n",
    "                optimizer_rescale_factor.zero_grad()\n",
    "                loss_rescale.backward()\n",
    "                optimizer_rescale_factor.step()\n",
    "\n",
    "        if (epoch % eval_every == 0):\n",
    "            eval_mse, eval_dtw, eval_tdi = eval_model(net, testloader, gamma)\n",
    "\n",
    "        t.set_postfix(loss=loss.item(),\n",
    "                      loss_shape=loss_shape.item(),\n",
    "                      loss_temporal=loss_temporal.item(),\n",
    "                      mse=eval_mse,\n",
    "                      dtw=eval_dtw,\n",
    "                      tdi=eval_tdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(net, loader, gamma):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    losses_mse = []\n",
    "    losses_dtw = []\n",
    "    losses_tdi = []\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        loss_mse, loss_dtw, loss_tdi = torch.tensor(\n",
    "            0), torch.tensor(0), torch.tensor(0)\n",
    "        # get the inputs\n",
    "        inputs, target = data\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size, N_output = target.shape[0:2]\n",
    "        outputs = net(inputs)\n",
    "        if len(outputs) == 2:\n",
    "            outputs, _ = outputs\n",
    "        else:\n",
    "            outputs, prewarp_outputs, warp_matrix = outputs\n",
    "\n",
    "        # MSE\n",
    "        loss_mse = criterion(target, outputs)\n",
    "        loss_dtw, loss_tdi = 0, 0\n",
    "        # DTW and TDI\n",
    "        for k in range(batch_size):\n",
    "            target_k_cpu = target[k, :, 0:1].view(-1).detach().cpu().numpy()\n",
    "            output_k_cpu = outputs[k, :, 0:1].view(-1).detach().cpu().numpy()\n",
    "\n",
    "            loss_dtw += dtw(target_k_cpu, output_k_cpu)\n",
    "            path, sim = dtw_path(target_k_cpu, output_k_cpu)\n",
    "\n",
    "            Dist = 0\n",
    "            for i, j in path:\n",
    "                Dist += (i - j) * (i - j)\n",
    "            loss_tdi += Dist / (N_output * N_output)\n",
    "\n",
    "        loss_dtw = loss_dtw / batch_size\n",
    "        loss_tdi = loss_tdi / batch_size\n",
    "\n",
    "        # print statistics\n",
    "        losses_mse.append(loss_mse.item())\n",
    "        losses_dtw.append(loss_dtw)\n",
    "        losses_tdi.append(loss_tdi)\n",
    "\n",
    "    return np.array(losses_mse).mean(), np.array(losses_dtw).mean(), np.array(losses_tdi).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, enc_hid_dim, dec_hid_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(input_dim, enc_hid_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          bidirectional=True,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "\n",
    "        outputs, hidden = self.rnn(src, hidden)\n",
    "\n",
    "        # outputs = [batch size, src len, hid dim * num directions]\n",
    "        # hidden = [n layers * num directions, batch size, hid dim]\n",
    "\n",
    "        hidden = torch.cat((hidden[::2, :, :], hidden[1::2, :, :]), dim=2)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = torch.tanh(self.fc(hidden))\n",
    "\n",
    "        # outputs = [batch size, src len, enc hid dim * 2]\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        # hidden = [batch size, src len, dec hid dim]\n",
    "        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "\n",
    "        energy = torch.tanh(\n",
    "            self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "\n",
    "        # energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        # attention= [batch size, src len]\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, enc_hid_dim, dec_hid_dim, fc_dim,\n",
    "                 num_layers, dropout, attention, bayesian=False, embed_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.fc_dim = fc_dim\n",
    "        \n",
    "        self.embed_dim = embed_dim if embed_dim is not None else 0\n",
    "        \n",
    "        self.bayesian = bayesian\n",
    "        \n",
    "        if self.bayesian:\n",
    "            self.out_log_sigma = nn.Linear(fc_dim + output_dim, output_dim)\n",
    "\n",
    "            self.rnn = nn.GRU((enc_hid_dim * 2) + (output_dim * 2),\n",
    "                              dec_hid_dim,\n",
    "                              num_layers=num_layers,\n",
    "                              batch_first=True,\n",
    "                              dropout=dropout)\n",
    "            self.fc = nn.Linear(\n",
    "                (enc_hid_dim * 2) + dec_hid_dim + (output_dim * 2) + self.embed_dim, fc_dim)\n",
    "\n",
    "        else:\n",
    "            self.rnn = nn.GRU((enc_hid_dim * 2) + output_dim,\n",
    "                              dec_hid_dim,\n",
    "                              num_layers=num_layers,\n",
    "                              batch_first=True,\n",
    "                              dropout=dropout)\n",
    "\n",
    "            self.fc = nn.Linear(\n",
    "                (enc_hid_dim * 2) + dec_hid_dim + output_dim + self.embed_dim, fc_dim)\n",
    "\n",
    "        self.out = nn.Linear(fc_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs, embeddings=None):\n",
    "\n",
    "        a = self.attention(hidden[-1, :, :], encoder_outputs)\n",
    "\n",
    "        # a = [batch size, src len]\n",
    "\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        # a = [batch size, 1, src len]\n",
    "\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "\n",
    "        # weighted = [batch size, 1, enc hid dim * 2]\n",
    "\n",
    "        rnn_input = torch.cat((inputs, weighted), dim=2)\n",
    "\n",
    "        # rnn_input = [batch size, 1, (enc hid dim * 2) + emb dim]\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        # output = [batch size, seq len, dec hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "\n",
    "        hidden_prediction = torch.cat((output, weighted, inputs), dim=2)\n",
    "        \n",
    "        if embeddings is not None:\n",
    "            hidden_prediction = torch.cat((hidden_prediction, embeddings), dim=2)\n",
    "        \n",
    "        hidden_prediction = self.fc(hidden_prediction)\n",
    "\n",
    "        prediction = self.out(F.relu(hidden_prediction))\n",
    "\n",
    "        # prediction = [batch size, output dim]\n",
    "\n",
    "        if not self.bayesian:\n",
    "            return prediction, hidden\n",
    "        else:\n",
    "            log_sigma = self.out_log_sigma(torch.cat([hidden_prediction, prediction], dim=-1))\n",
    "            return prediction, log_sigma, hidden\n",
    "\n",
    "\n",
    "class MetaEmbedder(nn.Module):\n",
    "    def __init__(self, cat_input_dim, num_input_dim, embed_dim):\n",
    "        \"\"\"cat_input_dim should be a tuple (nb_of_inputs, nb_of_categories)\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.cat_input_dim = cat_input_dim\n",
    "        self.num_input_dim = num_input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        # self.cat_module = nn.Embedding(cat_input_dim[1], embed_dim)\n",
    "        self.num_module = nn.Linear(num_input_dim, embed_dim)\n",
    "        #self.fc = nn.Linear(self.embed_dim * (cat_input_dim[0] + 1), self.enc_hid_dim * self.num_layers * 2)\n",
    "        self.fc = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, inputs_cat, inputs_num):\n",
    "        batch_size = inputs_cat.shape[0]\n",
    "        #x_cat = self.cat_module(inputs_cat).reshape(batch_size, -1)\n",
    "        x_num = F.relu(self.num_module(inputs_num))\n",
    "        #x = torch.cat([x_cat, x_num], dim=1)\n",
    "        x = x_num\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, target_size, embedder=None, mc_dropout=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        if not torch.cuda.is_available() and self.device is None: \n",
    "            self.device = -1\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.bayesian = self.decoder.bayesian\n",
    "        self.mc_dropout = mc_dropout\n",
    "        \n",
    "        if embedder is not None:\n",
    "            self.embedder = embedder\n",
    "        \n",
    "        if self.bayesian:\n",
    "            #Add a learnable rescale factor as in https://openreview.net/pdf?id=CecZ_0t79q\n",
    "            self.log_rescale_factor = nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "\n",
    "    def forward(self, src, meta_cat=None, meta_num=None):\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        \n",
    "        embeddings = None\n",
    "        if hasattr(self, 'embedder') and meta_cat is not None and meta_num is not None:\n",
    "            embeddings = self.embedder(meta_cat, meta_num).unsqueeze(1)\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size,\n",
    "                              self.target_size,\n",
    "                              self.decoder.output_dim).to(self.device)\n",
    "        hiddens = torch.zeros(batch_size,\n",
    "                              self.target_size,\n",
    "                              self.decoder.dec_hid_dim).to(self.device)\n",
    "        \n",
    "        if self.bayesian:\n",
    "            log_sigmas = torch.zeros(batch_size,\n",
    "                                     self.target_size,\n",
    "                                     self.decoder.output_dim).to(self.device)\n",
    "\n",
    "        inputs = src[:, -1, :].unsqueeze(1)\n",
    "        \n",
    "        if self.bayesian:\n",
    "            inputs = torch.cat([inputs, torch.zeros(*inputs.shape).to(inputs.device)], 2)\n",
    "\n",
    "        for t in range(0, self.target_size):\n",
    "            dec_outputs = self.decoder(inputs, hidden, encoder_outputs, embeddings=embeddings)\n",
    "\n",
    "            if not self.bayesian:\n",
    "                output, hidden = dec_outputs\n",
    "                outputs[:, t:t + 1, :] = output\n",
    "                hiddens[:, t:t + 1, :] = hidden[-2:-1, :, :].transpose(0, 1)\n",
    "\n",
    "                inputs = output\n",
    "            else:\n",
    "                output, log_sigma, hidden = dec_outputs\n",
    "                outputs[:, t:t + 1, :] = output\n",
    "                hiddens[:, t:t + 1, :] = hidden[-2:-1, :, :].transpose(0, 1)\n",
    "                log_sigmas[:, t:t+1, :] = log_sigma\n",
    "\n",
    "                inputs = torch.cat([output, log_sigma], dim=2)\n",
    "        \n",
    "        #if hasattr(self, 'rescale_factor'):\n",
    "        #    log_sigmas += 2 * self.rescale_factor\n",
    "\n",
    "        if not self.bayesian:\n",
    "            return outputs, hiddens\n",
    "        else:\n",
    "            return outputs, log_sigmas, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_net(dropout=0.5, bayesian=False, mc_dropout=False):\n",
    "    embedder = None\n",
    "    encoder = Encoder(input_dim= 1, enc_hid_dim=32, dec_hid_dim=32,\n",
    "                      num_layers=4, dropout=dropout\n",
    "                     ).to(device)\n",
    "    attention = Attention(enc_hid_dim=32, dec_hid_dim=32)\n",
    "    decoder = Decoder(output_dim= 1, enc_hid_dim=32, dec_hid_dim=32, fc_dim=32,\n",
    "                      num_layers=4, dropout=dropout, attention=attention, bayesian=bayesian,\n",
    "                      embed_dim = None\n",
    "                     ).to(device)\n",
    "    net = Seq2Seq(encoder, decoder, device, N_output, embedder=embedder, mc_dropout=False).to(device)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n",
      "10.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1db932355f4846b5a7cf17365d7329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=251.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.59 GiB already allocated; 11.16 MiB free; 2.79 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-0a86a719bc9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbayesian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     train_model(net, loss_type=['fake_baye'], optimizer_parameters=optimizer_parameters,\n\u001b[1;32m----> 9\u001b[1;33m             epochs=251, eval_every=10)\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mnets_lists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mse_ensembling'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-57fd43a27bed>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(net, loss_type, optimizer_parameters, epochs, gamma, eval_every, Lambda, alpha, beta)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\ml_mvp_1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-122-87982039448b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, meta_cat, meta_num)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\ml_mvp_1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-122-87982039448b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, hidden)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# outputs = [batch size, src len, hid dim * num directions]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\ml_mvp_1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\ml_mvp_1\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 740\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.59 GiB already allocated; 11.16 MiB free; 2.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())  \n",
    "print(torch.cuda.is_available())   \n",
    "print(torch.version.cuda) \n",
    "nets_lists = {}\n",
    "nets_lists['mse_ensembling'] = []\n",
    "for i in range(5):\n",
    "    net = gen_net(dropout=0.2, bayesian=True, mc_dropout=False)\n",
    "    train_model(net, loss_type=['fake_baye'], optimizer_parameters=optimizer_parameters,\n",
    "            epochs=251, eval_every=10)\n",
    "    nets_lists['mse_ensembling'].extend([net])\n",
    "\n",
    "[x.log_rescale_factor for x in nets_lists['mse_ensembling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
