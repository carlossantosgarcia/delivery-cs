{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Libelle Date et heure de comptage  Débit horaire  \\\n",
      "0      AV_Champs_Elysees       2019-11-01 04:00:00          746.0   \n",
      "1      AV_Champs_Elysees       2019-11-01 05:00:00          549.0   \n",
      "2      AV_Champs_Elysees       2019-11-01 06:00:00          503.0   \n",
      "3      AV_Champs_Elysees       2019-11-01 07:00:00          500.0   \n",
      "4      AV_Champs_Elysees       2019-11-01 08:00:00          525.0   \n",
      "...                  ...                       ...            ...   \n",
      "28259          Sts_Peres       2020-11-22 19:00:00          276.0   \n",
      "28260          Sts_Peres       2020-11-22 20:00:00          221.0   \n",
      "28261          Sts_Peres       2020-11-22 21:00:00          182.0   \n",
      "28262          Sts_Peres       2020-11-22 22:00:00          136.0   \n",
      "28263          Sts_Peres       2020-11-22 23:00:00           90.0   \n",
      "\n",
      "       Taux d'occupation  Etat trafic  Etat arc            filename  \\\n",
      "0               10.98889            1  Invalide  champs-elysees.csv   \n",
      "1                7.40722            1  Invalide  champs-elysees.csv   \n",
      "2                7.66667            1  Invalide  champs-elysees.csv   \n",
      "3                4.75500            1  Invalide  champs-elysees.csv   \n",
      "4                5.37389            1  Invalide  champs-elysees.csv   \n",
      "...                  ...          ...       ...                 ...   \n",
      "28259            3.34333            1  Invalide             sts.csv   \n",
      "28260            2.50222            1  Invalide             sts.csv   \n",
      "28261            2.03500            1  Invalide             sts.csv   \n",
      "28262            1.54834            1  Invalide             sts.csv   \n",
      "28263            1.32778            1  Invalide             sts.csv   \n",
      "\n",
      "             Date  Jour de la semaine_0  Jour de la semaine_1  ...  mintempC  \\\n",
      "0      2019-11-01                     0                     0  ...         9   \n",
      "1      2019-11-01                     0                     0  ...         9   \n",
      "2      2019-11-01                     0                     0  ...         9   \n",
      "3      2019-11-01                     0                     0  ...         9   \n",
      "4      2019-11-01                     0                     0  ...         9   \n",
      "...           ...                   ...                   ...  ...       ...   \n",
      "28259  2020-11-22                     0                     0  ...         7   \n",
      "28260  2020-11-22                     0                     0  ...         7   \n",
      "28261  2020-11-22                     0                     0  ...         7   \n",
      "28262  2020-11-22                     0                     0  ...         7   \n",
      "28263  2020-11-22                     0                     0  ...         7   \n",
      "\n",
      "       avgtempC  totalSnow_cm  sunHour  uvIndex             sunrise  \\\n",
      "0            13           0.0      3.7        3 2019-11-01 07:37:00   \n",
      "1            13           0.0      3.7        3 2019-11-01 07:37:00   \n",
      "2            13           0.0      3.7        3 2019-11-01 07:37:00   \n",
      "3            13           0.0      3.7        3 2019-11-01 07:37:00   \n",
      "4            13           0.0      3.7        3 2019-11-01 07:37:00   \n",
      "...         ...           ...      ...      ...                 ...   \n",
      "28259         9           0.0      5.1        3 2020-11-22 08:11:00   \n",
      "28260         9           0.0      5.1        3 2020-11-22 08:11:00   \n",
      "28261         9           0.0      5.1        3 2020-11-22 08:11:00   \n",
      "28262         9           0.0      5.1        3 2020-11-22 08:11:00   \n",
      "28263         9           0.0      5.1        3 2020-11-22 08:11:00   \n",
      "\n",
      "                   sunset       moon_phase  moon_illumination Journée  \n",
      "0     2019-11-01 17:31:00  Waxing Crescent                 24   False  \n",
      "1     2019-11-01 17:31:00  Waxing Crescent                 24   False  \n",
      "2     2019-11-01 17:31:00  Waxing Crescent                 24   False  \n",
      "3     2019-11-01 17:31:00  Waxing Crescent                 24   False  \n",
      "4     2019-11-01 17:31:00  Waxing Crescent                 24    True  \n",
      "...                   ...              ...                ...     ...  \n",
      "28259 2020-11-22 17:03:00    First Quarter                 47   False  \n",
      "28260 2020-11-22 17:03:00    First Quarter                 47   False  \n",
      "28261 2020-11-22 17:03:00    First Quarter                 47   False  \n",
      "28262 2020-11-22 17:03:00    First Quarter                 47   False  \n",
      "28263 2020-11-22 17:03:00    First Quarter                 47   False  \n",
      "\n",
      "[27782 rows x 47 columns]\n",
      "                 Libelle Date et heure de comptage  Débit horaire  \\\n",
      "9259   AV_Champs_Elysees       2020-11-23 00:00:00           91.0   \n",
      "9260   AV_Champs_Elysees       2020-11-23 01:00:00           63.0   \n",
      "9261   AV_Champs_Elysees       2020-11-23 02:00:00           47.0   \n",
      "9262   AV_Champs_Elysees       2020-11-23 03:00:00           51.0   \n",
      "9263   AV_Champs_Elysees       2020-11-23 04:00:00           32.0   \n",
      "...                  ...                       ...            ...   \n",
      "28500          Sts_Peres       2020-12-02 20:00:00          565.0   \n",
      "28501          Sts_Peres       2020-12-02 21:00:00          422.0   \n",
      "28502          Sts_Peres       2020-12-02 22:00:00          239.0   \n",
      "28503          Sts_Peres       2020-12-02 23:00:00          142.0   \n",
      "28504          Sts_Peres       2020-12-03 00:00:00          129.0   \n",
      "\n",
      "       Taux d'occupation  Etat trafic  Etat arc            filename  \\\n",
      "9259             1.38722            1  Invalide  champs-elysees.csv   \n",
      "9260             0.91056            1  Invalide  champs-elysees.csv   \n",
      "9261             0.74278            1  Invalide  champs-elysees.csv   \n",
      "9262             0.61056            1  Invalide  champs-elysees.csv   \n",
      "9263             0.35334            1  Invalide  champs-elysees.csv   \n",
      "...                  ...          ...       ...                 ...   \n",
      "28500            5.79944            1  Invalide             sts.csv   \n",
      "28501            3.94778            1  Invalide             sts.csv   \n",
      "28502            2.58000            1  Invalide             sts.csv   \n",
      "28503            1.83667            1  Invalide             sts.csv   \n",
      "28504            1.68500            1  Invalide             sts.csv   \n",
      "\n",
      "             Date  Jour de la semaine_0  Jour de la semaine_1  ...  mintempC  \\\n",
      "9259   2020-11-23                     1                     0  ...         8   \n",
      "9260   2020-11-23                     1                     0  ...         8   \n",
      "9261   2020-11-23                     1                     0  ...         8   \n",
      "9262   2020-11-23                     1                     0  ...         8   \n",
      "9263   2020-11-23                     1                     0  ...         8   \n",
      "...           ...                   ...                   ...  ...       ...   \n",
      "28500  2020-12-02                     0                     0  ...         6   \n",
      "28501  2020-12-02                     0                     0  ...         6   \n",
      "28502  2020-12-02                     0                     0  ...         6   \n",
      "28503  2020-12-02                     0                     0  ...         6   \n",
      "28504  2020-12-03                     0                     0  ...        -3   \n",
      "\n",
      "       avgtempC  totalSnow_cm  sunHour  uvIndex             sunrise  \\\n",
      "9259          9           0.0      3.3        2 2020-11-23 08:12:00   \n",
      "9260          9           0.0      3.3        2 2020-11-23 08:12:00   \n",
      "9261          9           0.0      3.3        2 2020-11-23 08:12:00   \n",
      "9262          9           0.0      3.3        2 2020-11-23 08:12:00   \n",
      "9263          9           0.0      3.3        2 2020-11-23 08:12:00   \n",
      "...         ...           ...      ...      ...                 ...   \n",
      "28500         7           0.0      3.1        2 2020-12-02 08:24:00   \n",
      "28501         7           0.0      3.1        2 2020-12-02 08:24:00   \n",
      "28502         7           0.0      3.1        2 2020-12-02 08:24:00   \n",
      "28503         7           0.0      3.1        2 2020-12-02 08:24:00   \n",
      "28504         7           0.0      3.1        3 2020-12-03 08:25:00   \n",
      "\n",
      "                   sunset      moon_phase  moon_illumination Journée  \n",
      "9259  2020-11-23 17:02:00   First Quarter                 54   False  \n",
      "9260  2020-11-23 17:02:00   First Quarter                 54   False  \n",
      "9261  2020-11-23 17:02:00   First Quarter                 54   False  \n",
      "9262  2020-11-23 17:02:00   First Quarter                 54   False  \n",
      "9263  2020-11-23 17:02:00   First Quarter                 54   False  \n",
      "...                   ...             ...                ...     ...  \n",
      "28500 2020-12-02 16:56:00  Waxing Gibbous                 82   False  \n",
      "28501 2020-12-02 16:56:00  Waxing Gibbous                 82   False  \n",
      "28502 2020-12-02 16:56:00  Waxing Gibbous                 82   False  \n",
      "28503 2020-12-02 16:56:00  Waxing Gibbous                 82   False  \n",
      "28504 2020-12-03 16:55:00  Waning Gibbous                 75   False  \n",
      "\n",
      "[723 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tslearn.metrics import dtw, dtw_path\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "\n",
    "df_train = pd.read_pickle(os.path.join(r\"data/df_train.pkl\"))\n",
    "\n",
    "df_test = pd.read_pickle(os.path.join(r\"data/df_test.pkl\"))\n",
    "\n",
    "print(df_train)\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2']\n",
      "[0.  1.2 1.6 0.8 2.7 3.6 1.8 1.3 0.9 0.1 0.2 0.7 1.  0.5 1.1 1.5 0.4 0.6\n",
      " 0.3 2.1 1.4 1.7 2.  1.9 2.6 3.5 2.2 2.4 3.2 4.4 5.9 3.  2.8 4.2 2.9 2.5\n",
      " 3.7 4.  3.8 2.3]\n"
     ]
    }
   ],
   "source": [
    "mapper = {'AV_Champs_Elysees': \"0\", 'Convention': \"1\", 'Sts_Peres': \"2\"}\n",
    "df_train['Libelle'] = df_train['Libelle'].map(mapper)\n",
    "df_test['Libelle'] = df_test['Libelle'].map(mapper)\n",
    "\n",
    "mapper_2 = {'Invalide': \"0\", 'Barré': \"1\"}\n",
    "df_train['Etat arc'] = df_train['Etat arc'].map(mapper_2)\n",
    "df_test['Etat arc'] = df_test['Etat arc'].map(mapper_2)\n",
    "print(df_train[\"Libelle\"].unique())\n",
    "\n",
    "print(df_train[\"precipMM\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Libelle', 'Date et heure de comptage', 'Débit horaire',\n",
      "       'Taux d'occupation', 'Etat trafic', 'Etat arc', 'filename', 'Date',\n",
      "       'Jour de la semaine_0', 'Jour de la semaine_1', 'Jour de la semaine_2',\n",
      "       'Jour de la semaine_3', 'Jour de la semaine_4', 'Jour de la semaine_5',\n",
      "       'Jour de la semaine_6', 'Etat du confinement', 'Couvre-feu',\n",
      "       'Jour férié', 'Vacances scolaires',\n",
      "       'Date des prochaines vacances scolaires',\n",
      "       'Temps avant les prochaines vacances scolaires', 'tempC',\n",
      "       'windspeedKmph', 'winddirDegree', 'weatherCode', 'precipMM', 'humidity',\n",
      "       'visibility', 'pressure', 'cloudcover', 'HeatIndexC', 'DewPointC',\n",
      "       'WindChillC', 'WindGustKmph', 'FeelsLikeC', 'uvIndex', 'maxtempC',\n",
      "       'mintempC', 'avgtempC', 'totalSnow_cm', 'sunHour', 'uvIndex', 'sunrise',\n",
      "       'sunset', 'moon_phase', 'moon_illumination', 'Journée'],\n",
      "      dtype='object')\n",
      "Libelle                                                   object\n",
      "Date et heure de comptage                         datetime64[ns]\n",
      "Débit horaire                                            float64\n",
      "Taux d'occupation                                        float64\n",
      "Etat trafic                                                int64\n",
      "Etat arc                                                  object\n",
      "filename                                                  object\n",
      "Date                                                      object\n",
      "Jour de la semaine_0                                       uint8\n",
      "Jour de la semaine_1                                       uint8\n",
      "Jour de la semaine_2                                       uint8\n",
      "Jour de la semaine_3                                       uint8\n",
      "Jour de la semaine_4                                       uint8\n",
      "Jour de la semaine_5                                       uint8\n",
      "Jour de la semaine_6                                       uint8\n",
      "Etat du confinement                                        int64\n",
      "Couvre-feu                                                  bool\n",
      "Jour férié                                                  bool\n",
      "Vacances scolaires                                          bool\n",
      "Date des prochaines vacances scolaires            datetime64[ns]\n",
      "Temps avant les prochaines vacances scolaires    timedelta64[ns]\n",
      "tempC                                                      int64\n",
      "windspeedKmph                                              int64\n",
      "winddirDegree                                              int64\n",
      "weatherCode                                                int64\n",
      "precipMM                                                 float64\n",
      "humidity                                                   int64\n",
      "visibility                                                 int64\n",
      "pressure                                                   int64\n",
      "cloudcover                                                 int64\n",
      "HeatIndexC                                                 int64\n",
      "DewPointC                                                  int64\n",
      "WindChillC                                                 int64\n",
      "WindGustKmph                                               int64\n",
      "FeelsLikeC                                                 int64\n",
      "uvIndex                                                    int64\n",
      "maxtempC                                                   int64\n",
      "mintempC                                                   int64\n",
      "avgtempC                                                   int64\n",
      "totalSnow_cm                                             float64\n",
      "sunHour                                                  float64\n",
      "uvIndex                                                    int64\n",
      "sunrise                                           datetime64[ns]\n",
      "sunset                                            datetime64[ns]\n",
      "moon_phase                                                object\n",
      "moon_illumination                                          int64\n",
      "Journée                                                     bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "cat_columns = [\"Etat trafic\", \"Etat arc\", 'Jour de la semaine_0', 'Jour de la semaine_1', 'Jour de la semaine_2',\n",
    "       'Jour de la semaine_3', 'Jour de la semaine_4', 'Jour de la semaine_5',\n",
    "       'Jour de la semaine_6', 'Etat du confinement', 'Couvre-feu',\n",
    "       'Jour férié', 'Vacances scolaires']\n",
    "bool_columns = ['Couvre-feu',\n",
    "       'Jour férié', 'Vacances scolaires']\n",
    "object_columns = [\"Etat arc\"]\n",
    "# df_meta_train = pd.DataFrame()\n",
    "# #df_meta_train[cat_columns] = df_train[cat_columns].apply(lambda x: x.astype(pd.CategoricalDtype(categories=df_meta.index)).cat.codes)\n",
    "# df_meta_train[cat_columns] = df_train[cat_columns]\n",
    "# df_meta_train['Libelle'] = df_train[\"Libelle\"].astype(str)\n",
    "# df_meta_train.index = df_meta_train['Libelle']\n",
    "\n",
    "# df_meta_test = pd.DataFrame()\n",
    "# #df_meta_train[cat_columns] = df_train[cat_columns].apply(lambda x: x.astype(pd.CategoricalDtype(categories=df_meta.index)).cat.codes)\n",
    "# df_meta_test[cat_columns] = df_test[cat_columns]\n",
    "# df_meta_test['Libelle'] = df_test[\"Libelle\"].astype(str)\n",
    "# df_meta_test.index = df_meta_test['Libelle']\n",
    "\n",
    "# print(df_meta_test.index)\n",
    "# print(df_meta_train['Etat arc'].unique())\n",
    "\n",
    "\n",
    "# cat_code = dict(enumerate(df_meta_train.index))\n",
    "# cat_code_reverse = {v:k for k,v in cat_code.items()}\n",
    "\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, size, step):\n",
    "    \"\"\" Yield successive n-sized chunks from l.\n",
    "    \"\"\"\n",
    "    l = l[:(len(l) // size) * size]\n",
    "    return [x for x in [l[i : i + size] for i in range(0, len(l), step)] if len(x) == size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "28259    2\n",
      "28260    2\n",
      "28261    2\n",
      "28262    2\n",
      "28263    2\n",
      "Name: Libelle, Length: 27782, dtype: object\n",
      "['0' '1' '2']\n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4         True\n",
      "         ...  \n",
      "28259    False\n",
      "28260    False\n",
      "28261    False\n",
      "28262    False\n",
      "28263    False\n",
      "Name: Journée, Length: 27782, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"Libelle\"])\n",
    "print(df_test[\"Libelle\"].unique())\n",
    "print(df_train['Journée'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramètres\n",
    "N_input = 14*24\n",
    "N_output = 7*24\n",
    "device = 'cuda'\n",
    "#p_test = 0.2\n",
    "#meta_specs = {'cat_input_dim': (len(cat_columns), len(df_meta_train.index)),\n",
    "#              'embed_dim': 8}\n",
    "optimizer_parameters = {'lr': 0.001}\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Libelle Date et heure de comptage  Débit horaire  Taux d'occupation  \\\n",
      "9259        0       2020-11-23 00:00:00           91.0            1.38722   \n",
      "9260        0       2020-11-23 01:00:00           63.0            0.91056   \n",
      "9261        0       2020-11-23 02:00:00           47.0            0.74278   \n",
      "9262        0       2020-11-23 03:00:00           51.0            0.61056   \n",
      "9263        0       2020-11-23 04:00:00           32.0            0.35334   \n",
      "...       ...                       ...            ...                ...   \n",
      "28500       2       2020-12-02 20:00:00          565.0            5.79944   \n",
      "28501       2       2020-12-02 21:00:00          422.0            3.94778   \n",
      "28502       2       2020-12-02 22:00:00          239.0            2.58000   \n",
      "28503       2       2020-12-02 23:00:00          142.0            1.83667   \n",
      "28504       2       2020-12-03 00:00:00          129.0            1.68500   \n",
      "\n",
      "       Etat trafic  Etat arc            filename        Date  \\\n",
      "9259             1         0  champs-elysees.csv  2020-11-23   \n",
      "9260             1         0  champs-elysees.csv  2020-11-23   \n",
      "9261             1         0  champs-elysees.csv  2020-11-23   \n",
      "9262             1         0  champs-elysees.csv  2020-11-23   \n",
      "9263             1         0  champs-elysees.csv  2020-11-23   \n",
      "...            ...       ...                 ...         ...   \n",
      "28500            1         0             sts.csv  2020-12-02   \n",
      "28501            1         0             sts.csv  2020-12-02   \n",
      "28502            1         0             sts.csv  2020-12-02   \n",
      "28503            1         0             sts.csv  2020-12-02   \n",
      "28504            1         0             sts.csv  2020-12-03   \n",
      "\n",
      "       Jour de la semaine_0  Jour de la semaine_1  ...  mintempC  avgtempC  \\\n",
      "9259                      1                     0  ...         8         9   \n",
      "9260                      1                     0  ...         8         9   \n",
      "9261                      1                     0  ...         8         9   \n",
      "9262                      1                     0  ...         8         9   \n",
      "9263                      1                     0  ...         8         9   \n",
      "...                     ...                   ...  ...       ...       ...   \n",
      "28500                     0                     0  ...         6         7   \n",
      "28501                     0                     0  ...         6         7   \n",
      "28502                     0                     0  ...         6         7   \n",
      "28503                     0                     0  ...         6         7   \n",
      "28504                     0                     0  ...        -3         7   \n",
      "\n",
      "       totalSnow_cm  sunHour  uvIndex             sunrise              sunset  \\\n",
      "9259            0.0      3.3        2 2020-11-23 08:12:00 2020-11-23 17:02:00   \n",
      "9260            0.0      3.3        2 2020-11-23 08:12:00 2020-11-23 17:02:00   \n",
      "9261            0.0      3.3        2 2020-11-23 08:12:00 2020-11-23 17:02:00   \n",
      "9262            0.0      3.3        2 2020-11-23 08:12:00 2020-11-23 17:02:00   \n",
      "9263            0.0      3.3        2 2020-11-23 08:12:00 2020-11-23 17:02:00   \n",
      "...             ...      ...      ...                 ...                 ...   \n",
      "28500           0.0      3.1        2 2020-12-02 08:24:00 2020-12-02 16:56:00   \n",
      "28501           0.0      3.1        2 2020-12-02 08:24:00 2020-12-02 16:56:00   \n",
      "28502           0.0      3.1        2 2020-12-02 08:24:00 2020-12-02 16:56:00   \n",
      "28503           0.0      3.1        2 2020-12-02 08:24:00 2020-12-02 16:56:00   \n",
      "28504           0.0      3.1        3 2020-12-03 08:25:00 2020-12-03 16:55:00   \n",
      "\n",
      "           moon_phase  moon_illumination Journée  \n",
      "9259    First Quarter                 54   False  \n",
      "9260    First Quarter                 54   False  \n",
      "9261    First Quarter                 54   False  \n",
      "9262    First Quarter                 54   False  \n",
      "9263    First Quarter                 54   False  \n",
      "...               ...                ...     ...  \n",
      "28500  Waxing Gibbous                 82   False  \n",
      "28501  Waxing Gibbous                 82   False  \n",
      "28502  Waxing Gibbous                 82   False  \n",
      "28503  Waxing Gibbous                 82   False  \n",
      "28504  Waning Gibbous                 75   False  \n",
      "\n",
      "[723 rows x 47 columns]\n",
      "Libelle\n",
      "0    []\n",
      "1    []\n",
      "2    []\n",
      "dtype: object\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#visibility \n",
    "metatemp_columns = cat_columns + ['windspeedKmph', 'weatherCode', 'precipMM', 'cloudcover', 'HeatIndexC', 'maxtempC', 'mintempC']\n",
    "num_columns = ['windspeedKmph', 'weatherCode', 'precipMM', 'cloudcover', 'HeatIndexC', 'maxtempC', 'mintempC']\n",
    "df_train[bool_columns] = df_train[bool_columns].apply(lambda x : x.astype(int))\n",
    "df_test[bool_columns] = df_test[bool_columns].apply(lambda x : x.astype(int))\n",
    "df_train[object_columns] = df_train[object_columns].apply(lambda x : x.astype(int))\n",
    "df_test[object_columns] = df_test[object_columns].apply(lambda x : x.astype(int))\n",
    "print(df_test)\n",
    "#std_scaler = MinMaxScaler().fit(df_train[num_columns])\n",
    "#df_std = std_scaler.transform(df_train[num_columns])\n",
    "#print(df_std.head())\n",
    "#print(df_train.dtypes)\n",
    "metatemp_data_train = df_train.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')[metatemp_columns].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "metatemp_data_test = df_test.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')[metatemp_columns].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "print(metatemp_data_test.head())\n",
    "\n",
    "print(metatemp_data_test[0])\n",
    "print(len(metatemp_data_test.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libelle\n",
      "0    []\n",
      "1    []\n",
      "2    []\n",
      "Name: Débit horaire, dtype: object\n",
      "[]\n",
      "['0' '1' '2']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_train = df_train.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')['Débit horaire'].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "data_test = df_test.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')['Débit horaire'].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "print(data_test.head())\n",
    "# metadata_train =df_train.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')['Débit horaire',\"Taux d'occupation\"].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "# metadata_test = df_meta_test.sort_values(['Date et heure de comptage', 'Libelle']).groupby('Libelle')['Débit horaire',\"Taux d'occupation\"].apply(lambda x: chunks(x.values, size=N_input+N_output, step=1))\n",
    "\n",
    "#print(data.values)\n",
    "data_numpy_train = np.array([np.array(x) for x in data_train.values])\n",
    "data_numpy_test = np.array([np.array(x) for x in data_test.values])\n",
    "metatemp_data_numpy_train = np.array([np.array(x) for x in metatemp_data_train.values])\n",
    "metatemp_data_numpy_test = np.array([np.array(x) for x in metatemp_data_test.values])\n",
    "#data_numpy.astype(float)\n",
    "\n",
    "print(metatemp_data_numpy_test)\n",
    "\n",
    "rues = np.array([x for x in data_train.index])\n",
    "\n",
    "\n",
    "# meta_cat_train = metadata_train[cat_columns].values.astype(int)\n",
    "# meta_cat_train = np.array([np.array(x) for x in meta_cat_train.values])\n",
    "\n",
    "# metadata_test = df_meta_test.loc[rues]\n",
    "# meta_cat_test = metadata_test[cat_columns].values.astype(int)\n",
    "# meta_cat_test = np.array([np.array(x) for x in meta_cat_test.values])\n",
    "print(rues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(8569, 504, 20)\n",
      "(8569, 504)\n",
      "[  1.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   1.   1.  11.\n",
      " 143.   0.  79.  11.  16.   9.]\n"
     ]
    }
   ],
   "source": [
    "# Mélange les rues\n",
    "print(len(data_numpy_train)==len(metatemp_data_numpy_train))\n",
    "ind_train = np.arange(len(data_numpy_train))\n",
    "np.random.shuffle(ind_train)\n",
    "ind_test = np.arange(len(data_numpy_test))\n",
    "np.random.shuffle(ind_test)\n",
    "data_numpy_train = data_numpy_train[ind_train]\n",
    "data_numpy_test = data_numpy_test[ind_test]\n",
    "# meta_cat_train = meta_cat_train[ind_train]\n",
    "# meta_cat_test = meta_cat_test[ind_test]\n",
    "metatemp_data_numpy_train = metatemp_data_numpy_train[ind_train]\n",
    "metatemp_data_numpy_test = metatemp_data_numpy_test[ind_test]\n",
    "print(metatemp_data_numpy_train[0].shape)\n",
    "print(data_numpy_train[0].shape)\n",
    "\n",
    "\n",
    "print(metatemp_data_numpy_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25707, 504, 20)\n",
      "[ 11. 143.   0.  79.  11.  16.   9.]\n"
     ]
    }
   ],
   "source": [
    "# Concatène chaque départements ensembles\n",
    "\n",
    "# meta_cat_train = np.concatenate(meta_cat_train)\n",
    "# meta_cat_test = np.concatenate(meta_cat_test)\n",
    "data_numpy_train = np.concatenate(data_numpy_train)\n",
    "data_numpy_test = np.concatenate(data_numpy_test)\n",
    "metatemp_data_numpy_train = np.concatenate(metatemp_data_numpy_train)\n",
    "metatemp_data_numpy_test = np.concatenate(metatemp_data_numpy_test)\n",
    "\n",
    "data_numpy_train[data_numpy_train < 0] = 0\n",
    "data_numpy_test[data_numpy_test < 0] = 0\n",
    "print(metatemp_data_numpy_train.shape)\n",
    "print(metatemp_data_numpy_train[0][0][13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.45623426e-01 6.84070204e-02 3.50731084e-01 3.50731084e-01\n",
      " 3.50731084e-01 3.48061820e-01 3.50731084e-01 3.47981525e-01\n",
      " 3.50493665e-01 1.01827417e+00 2.22373167e-01 1.67590509e-01\n",
      " 4.73074000e-01 6.63581932e+00 7.51116639e+01 3.10257589e-01\n",
      " 3.42995536e+01 7.15701991e+00 7.75204422e+00 5.86710296e+00]\n",
      "[-0.4147338  -0.1850467  -0.31250337  0.84064442 -0.50419954 -0.22092211\n",
      " -0.36317187]\n"
     ]
    }
   ],
   "source": [
    "# Normalise par mean-std calculées sur le data de train\n",
    "std = data_numpy_train.std((0,1))[None]\n",
    "mean = data_numpy_train.mean((0,1))[None]\n",
    "meta_std = metatemp_data_numpy_train[:][:][13:].std((0,1))[None]\n",
    "meta_mean = metatemp_data_numpy_train[:][:][13:].mean((0,1))[None]\n",
    "print(meta_std[None][0][0])\n",
    "\n",
    "\n",
    "data_numpy_train = (data_numpy_train-mean[None])/std[None]\n",
    "data_numpy_test = (data_numpy_test-mean[None])/std[None]\n",
    "for i in range (len(metatemp_data_numpy_train)):\n",
    "    for j in range (len(metatemp_data_numpy_train[i])):\n",
    "        for k in range (len(num_columns)):\n",
    "            metatemp_data_numpy_train[i][j][len(cat_columns)+k] = (metatemp_data_numpy_train[i][j][len(cat_columns)+k]-meta_mean[None][0][0][len(cat_columns)+k])/meta_std[None][0][0][len(cat_columns)+k]\n",
    "\n",
    "for i in range (len(metatemp_data_numpy_test)):\n",
    "    for j in range (len(metatemp_data_numpy_test[i])):\n",
    "        for k in range (len(num_columns)):\n",
    "            metatemp_data_numpy_test[i][j][len(cat_columns)+k] = (metatemp_data_numpy_test[i][j][len(cat_columns)+k]-meta_mean[None][0][0][len(cat_columns)+k])/meta_std[None][0][0][len(cat_columns)+k]\n",
    "print(metatemp_data_numpy_train[0][0][13:])\n",
    "\n",
    "def rescale(data):\n",
    "    return data * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-da830565830c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetatemp_data_numpy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_meta_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_meta_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetatemp_data_numpy_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mN_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetatemp_data_numpy_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_meta_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_meta_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetatemp_data_numpy_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mN_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetatemp_data_numpy_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Sépare en input/output\n",
    "X_train, y_train = data_numpy_train[:, :N_input], data_numpy_train[:, N_input:]\n",
    "X_test, y_test = data_numpy_test[:, :N_input], data_numpy_test[:, N_input:]\n",
    "print(metatemp_data_numpy_test)\n",
    "X_meta_train, y_meta_train = metatemp_data_numpy_train[:, :N_input, :], metatemp_data_numpy_train[:, N_input:, :]\n",
    "X_meta_test, y_meta_test = metatemp_data_numpy_test[:, :N_input, :], metatemp_data_numpy_test[:, N_input:, :]\n",
    "X_train = X_train[:,:,None]\n",
    "y_train = y_train[:,:,None]\n",
    "X_test = X_test[:,:,None]\n",
    "y_test = y_test[:,:,None]\n",
    "print(X_train.shape)\n",
    "print(X_meta_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "\n",
    "#import torch\n",
    "\n",
    "#print(type(X_train))\n",
    "#print(data_numpy.dtype)\n",
    "#print(torch.from_numpy(X_train))\n",
    "#print(torch.from_numpy(y_train))\n",
    "#print(torch.from_numpy(y_meta_train))\n",
    "\n",
    "dataset_train = torch.utils.data.TensorDataset(torch.FloatTensor(X_train),\n",
    "                                                torch.FloatTensor(X_meta_train),\n",
    "                                               torch.FloatTensor(y_train),\n",
    "                                              torch.FloatTensor(y_meta_train))\n",
    "dataset_test = torch.utils.data.TensorDataset(torch.FloatTensor(X_test),\n",
    "                                              torch.FloatTensor(X_meta_test),\n",
    "                                              torch.FloatTensor(y_test),\n",
    "                                             torch.FloatTensor(y_meta_test))\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs, metatemp_inputs, target, metatemp_target = data\n",
    "    print(inputs)\n",
    "    print(metatemp_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_baye(outputs, log_sigmas, target):\n",
    "    loss = 1/2 * (log_sigmas + torch.exp(-log_sigmas) * (outputs - target)**2)\n",
    "    return loss.mean()\n",
    "\n",
    "def loss_rescale_factor(log_rescale_factor, outputs, log_sigmas, target):\n",
    "    batch_size = outputs.shape[0]\n",
    "    loss = 1/2 * torch.exp(-2 * log_rescale_factor) * torch.sum(torch.exp(-log_sigmas) * (outputs - target)**2)\n",
    "    loss += batch_size * log_rescale_factor\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train_model(net, loss_type, optimizer_parameters, epochs=1000, gamma=0.001,\n",
    "                eval_every=50, Lambda=1, alpha=0.5, beta=0.):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), **optimizer_parameters)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    if hasattr(net, 'log_rescale_factor'):\n",
    "        optimizer_rescale_factor = torch.optim.Adam([net.log_rescale_factor], **optimizer_parameters)\n",
    "\n",
    "    t = tqdm.notebook.tqdm(range(epochs))\n",
    "    for epoch in t:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            net.train()\n",
    "            if hasattr(net, 'log_rescale_factor'):\n",
    "                net.log_rescale_factor.require_grad = False\n",
    "            \n",
    "            \n",
    "            inputs, metatemp_inputs, target, metatemp_target = data\n",
    "            inputs = inputs.to(device)\n",
    "            metatemp_inputs = metatemp_inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            metatemp_target = metatemp_target.to(device)\n",
    "            batch_size, N_output = target.shape[0:2]\n",
    "            #print(inputs)\n",
    "            #print(metatemp_inputs)\n",
    "            # forward + backward + optimize\n",
    "            \n",
    "            outputs = net(inputs, meta_temporal_input=metatemp_inputs, meta_temporal_target=metatemp_target)\n",
    "            if len(outputs) == 2:\n",
    "                outputs, _ = outputs\n",
    "            else:\n",
    "                outputs, log_sigmas, _ = outputs\n",
    "\n",
    "            loss_mse, loss_shape, loss_temporal = torch.tensor(\n",
    "                0), torch.tensor(0), torch.tensor(0)\n",
    "\n",
    "            loss = 0\n",
    "            if 'mse' in loss_type:\n",
    "                loss_mse = 100 * criterion(outputs, target)\n",
    "                loss += loss_mse\n",
    "\n",
    "            if 'dilate' in loss_type:\n",
    "                loss_dilate, loss_shape, loss_temporal = dilate_loss(\n",
    "                    outputs, target, alpha, gamma, device)\n",
    "                loss += loss_dilate\n",
    "\n",
    "            if 'fake_baye' in loss_type:\n",
    "                loss_fake_baye = fake_baye(outputs, log_sigmas, target)\n",
    "                loss += loss_fake_baye\n",
    "\n",
    "            if 'all_target_regression' in loss_type:\n",
    "                loss_target_week_regression = F.mse_loss(outputs.sum(1), target.sum(1))\n",
    "                loss += loss_target_week_regression\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if hasattr(net, 'log_rescale_factor'):\n",
    "                net.log_rescale_factor.require_grad = True\n",
    "\n",
    "                loss_rescale = loss_rescale_factor(net.log_rescale_factor, outputs.detach(), log_sigmas.detach(),\n",
    "                                                   target)\n",
    "                optimizer_rescale_factor.zero_grad()\n",
    "                loss_rescale.backward()\n",
    "                optimizer_rescale_factor.step()\n",
    "\n",
    "        if (epoch % eval_every == 0):\n",
    "            eval_mse, eval_dtw, eval_tdi = eval_model(net, testloader, gamma)\n",
    "\n",
    "        t.set_postfix(loss=loss.item(),\n",
    "                      loss_shape=loss_shape.item(),\n",
    "                      loss_temporal=loss_temporal.item(),\n",
    "                      mse=eval_mse,\n",
    "                      dtw=eval_dtw,\n",
    "                      tdi=eval_tdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(net, loader, gamma):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    losses_mse = []\n",
    "    losses_dtw = []\n",
    "    losses_tdi = []\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        loss_mse, loss_dtw, loss_tdi = torch.tensor(\n",
    "            0), torch.tensor(0), torch.tensor(0)\n",
    "        # get the inputs\n",
    "        inputs, metatemp_inputs, target, metatemp_target = data\n",
    "        inputs = inputs.to(device)\n",
    "        metatemp_inputs = metatemp_inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        metatemp_target = metatemp_target.to(device)\n",
    "        batch_size, N_output = target.shape[0:2]\n",
    "        outputs = net(inputs, meta_temporal_input=metatemp_inputs, meta_temporal_target=metatemp_target)\n",
    "        if len(outputs) == 2:\n",
    "            outputs, _ = outputs\n",
    "        else:\n",
    "            outputs, prewarp_outputs, warp_matrix = outputs\n",
    "\n",
    "        # MSE\n",
    "        loss_mse = criterion(target, outputs)\n",
    "        loss_dtw, loss_tdi = 0, 0\n",
    "        # DTW and TDI\n",
    "        for k in range(batch_size):\n",
    "            target_k_cpu = target[k, :, 0:1].view(-1).detach().cpu().numpy()\n",
    "            output_k_cpu = outputs[k, :, 0:1].view(-1).detach().cpu().numpy()\n",
    "\n",
    "            loss_dtw += dtw(target_k_cpu, output_k_cpu)\n",
    "            path, sim = dtw_path(target_k_cpu, output_k_cpu)\n",
    "\n",
    "            Dist = 0\n",
    "            for i, j in path:\n",
    "                Dist += (i - j) * (i - j)\n",
    "            loss_tdi += Dist / (N_output * N_output)\n",
    "\n",
    "        loss_dtw = loss_dtw / batch_size\n",
    "        loss_tdi = loss_tdi / batch_size\n",
    "\n",
    "        # print statistics\n",
    "        losses_mse.append(loss_mse.item())\n",
    "        losses_dtw.append(loss_dtw)\n",
    "        losses_tdi.append(loss_tdi)\n",
    "\n",
    "    return np.array(losses_mse).mean(), np.array(losses_dtw).mean(), np.array(losses_tdi).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, enc_hid_dim, dec_hid_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.num_layers = num_layers\n",
    "      \n",
    "        self.rnn = nn.GRU(input_dim, enc_hid_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          bidirectional=True,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, meta_temporal, hidden=None):\n",
    "       \n",
    "        if meta_temporal is not None:\n",
    "            src = torch.cat([src, meta_temporal], dim=2)\n",
    "        \n",
    "        \n",
    "\n",
    "        outputs, hidden = self.rnn(src, hidden)\n",
    "\n",
    "        # outputs = [batch size, src len, hid dim * num directions]\n",
    "        # hidden = [n layers * num directions, batch size, hid dim]\n",
    "\n",
    "        hidden = torch.cat((hidden[::2, :, :], hidden[1::2, :, :]), dim=2)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = torch.tanh(self.fc(hidden))\n",
    "\n",
    "        # outputs = [batch size, src len, enc hid dim * 2]\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        # hidden = [batch size, src len, dec hid dim]\n",
    "        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "\n",
    "        energy = torch.tanh(\n",
    "            self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "\n",
    "        # energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        # attention= [batch size, src len]\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, enc_hid_dim, dec_hid_dim, fc_dim,\n",
    "                 num_layers, dropout, attention, meta_temporal_dim, bayesian=False, embed_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.fc_dim = fc_dim\n",
    "        \n",
    "        self.embed_dim = embed_dim if embed_dim is not None else 0\n",
    "        self.meta_temporal_dim = meta_temporal_dim if meta_temporal_dim is not None else 0\n",
    "        \n",
    "        self.bayesian = bayesian\n",
    "        \n",
    "        if self.bayesian:\n",
    "            self.out_log_sigma = nn.Linear(fc_dim + output_dim, output_dim)\n",
    "\n",
    "            self.rnn = nn.GRU((enc_hid_dim * 2) + (input_dim * 2) + meta_temporal_dim,\n",
    "                              dec_hid_dim,\n",
    "                              num_layers=num_layers,\n",
    "                              batch_first=True,\n",
    "                              dropout=dropout)\n",
    "            self.fc_1 = nn.Linear(\n",
    "                (enc_hid_dim * 2) + dec_hid_dim + (input_dim * 2) + self.embed_dim, fc_dim)\n",
    "\n",
    "        else:\n",
    "            self.rnn = nn.GRU((enc_hid_dim * 2) + output_dim + meta_temporal_dim,\n",
    "                              dec_hid_dim,\n",
    "                              num_layers=num_layers,\n",
    "                              batch_first=True,\n",
    "                              dropout=dropout)\n",
    "\n",
    "            self.fc_1 = nn.Linear(\n",
    "                (enc_hid_dim * 2) + dec_hid_dim + output_dim + self.embed_dim, fc_dim)\n",
    "        \n",
    "        self.fc_2 = nn.Linear(fc_dim, fc_dim)\n",
    "        self.out = nn.Linear(fc_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs, meta_temporal, embeddings=None):\n",
    "\n",
    "        a = self.attention(hidden[-1, :, :], encoder_outputs)\n",
    "\n",
    "        # a = [batch size, src len]\n",
    "\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        # a = [batch size, 1, src len]\n",
    "\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "\n",
    "        # weighted = [batch size, 1, enc hid dim * 2]\n",
    "\n",
    "        if meta_temporal is not None:\n",
    "            rnn_input = torch.cat((inputs, meta_temporal, weighted), dim=2)\n",
    "        else:\n",
    "            rnn_input = torch.cat((inputs, weighted), dim=2)\n",
    "\n",
    "        # rnn_input = [batch size, 1, (enc hid dim * 2) + emb dim]\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        # output = [batch size, seq len, dec hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "\n",
    "        hidden_prediction = torch.cat((output, weighted, inputs), dim=2)\n",
    "        \n",
    "        if embeddings is not None:\n",
    "            hidden_prediction = torch.cat((hidden_prediction, embeddings), dim=2)\n",
    "        \n",
    "        #hidden_prediction = self.fc(hidden_prediction)\n",
    "        hidden_prediction = self.fc_1(F.relu(hidden_prediction))\n",
    "        hidden_prediction = self.fc_2(F.relu(hidden_prediction))\n",
    "\n",
    "        prediction = self.out(F.relu(hidden_prediction))\n",
    "\n",
    "        # prediction = [batch size, output dim]\n",
    "\n",
    "        if not self.bayesian:\n",
    "            return prediction, hidden\n",
    "        else:\n",
    "            log_sigma = self.out_log_sigma(torch.cat([hidden_prediction, prediction], dim=-1))\n",
    "            return prediction, log_sigma, hidden\n",
    "\n",
    "\n",
    "class MetaEmbedder(nn.Module):\n",
    "    def __init__(self, cat_input_dim, num_input_dim, embed_dim):\n",
    "        \"\"\"cat_input_dim should be a tuple (nb_of_inputs, nb_of_categories)\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.cat_input_dim = cat_input_dim\n",
    "        self.num_input_dim = num_input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        # self.cat_module = nn.Embedding(cat_input_dim[1], embed_dim)\n",
    "        self.num_module = nn.Linear(num_input_dim, embed_dim)\n",
    "        #self.fc = nn.Linear(self.embed_dim * (cat_input_dim[0] + 1), self.enc_hid_dim * self.num_layers * 2)\n",
    "        self.fc = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, inputs_cat, inputs_num):\n",
    "        batch_size = inputs_cat.shape[0]\n",
    "        #x_cat = self.cat_module(inputs_cat).reshape(batch_size, -1)\n",
    "        x_num = F.relu(self.num_module(inputs_num))\n",
    "        #x = torch.cat([x_cat, x_num], dim=1)\n",
    "        x = x_num\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, target_size, embedder=None, mc_dropout=False,\n",
    "                use_meta_temporal=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        if not torch.cuda.is_available() and self.device is None: \n",
    "            self.device = -1\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.bayesian = self.decoder.bayesian\n",
    "        self.mc_dropout = mc_dropout\n",
    "        self.use_meta_temporal = use_meta_temporal\n",
    "        \n",
    "        if embedder is not None:\n",
    "            self.embedder = embedder\n",
    "        \n",
    "        if self.bayesian:\n",
    "            #Add a learnable rescale factor as in https://openreview.net/pdf?id=CecZ_0t79q\n",
    "            self.log_rescale_factor = nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "\n",
    "    def forward(self, src, meta_temporal_input, meta_temporal_target, meta_cat=None, meta_num=None,\n",
    "               ):\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        if not self.use_meta_temporal:\n",
    "            meta_temporal_input = None\n",
    "            meta_temporal_target = None\n",
    "        \n",
    "        #print(src)\n",
    "        #print(meta_temporal_input)\n",
    "        encoder_outputs, hidden = self.encoder(src, meta_temporal=meta_temporal_input)\n",
    "        \n",
    "        embeddings = None\n",
    "        if hasattr(self, 'embedder') and meta_cat is not None and meta_num is not None:\n",
    "            embeddings = self.embedder(meta_cat, meta_num).unsqueeze(1)\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size,\n",
    "                              self.target_size,\n",
    "                              self.decoder.output_dim).to(self.device)\n",
    "        hiddens = torch.zeros(batch_size,\n",
    "                              self.target_size,\n",
    "                              self.decoder.dec_hid_dim).to(self.device)\n",
    "        \n",
    "        if self.bayesian:\n",
    "            log_sigmas = torch.zeros(batch_size,\n",
    "                                     self.target_size,\n",
    "                                     self.decoder.output_dim).to(self.device)\n",
    "\n",
    "        inputs = src[:, -1, :].unsqueeze(1)\n",
    "        \n",
    "        if self.bayesian:\n",
    "            inputs = torch.cat([inputs, torch.zeros(*inputs.shape).to(inputs.device)], 2)\n",
    "\n",
    "        for t in range(0, self.target_size):\n",
    "            meta_temporal = meta_temporal_target[:, t:t + 1, :] if meta_temporal_target is not None else None\n",
    "            dec_outputs = self.decoder(inputs, hidden, encoder_outputs, embeddings=embeddings,\n",
    "                                      meta_temporal=meta_temporal)\n",
    "\n",
    "            if not self.bayesian:\n",
    "                output, hidden = dec_outputs\n",
    "                outputs[:, t:t + 1, :] = output\n",
    "                hiddens[:, t:t + 1, :] = hidden[-2:-1, :, :].transpose(0, 1)\n",
    "\n",
    "                inputs = output\n",
    "            else:\n",
    "                output, log_sigma, hidden = dec_outputs\n",
    "                outputs[:, t:t + 1, :] = output\n",
    "                hiddens[:, t:t + 1, :] = hidden[-2:-1, :, :].transpose(0, 1)\n",
    "                log_sigmas[:, t:t+1, :] = log_sigma\n",
    "\n",
    "                inputs = torch.cat([output, log_sigma], dim=2)\n",
    "        \n",
    "        #if hasattr(self, 'rescale_factor'):\n",
    "        #    log_sigmas += 2 * self.rescale_factor\n",
    "\n",
    "        if not self.bayesian:\n",
    "            return outputs, hiddens\n",
    "        else:\n",
    "            return outputs, log_sigmas, hiddens\n",
    "\n",
    "def activate_mc_dropout(model):\n",
    "    for m in model.modules():\n",
    "        if (type(m) == nn.Dropout) or (type(m) == nn.GRU):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_net(dropout=0.5, bayesian=False, mc_dropout=False, meta_temporal=True):\n",
    "    embedder = None\n",
    "    \n",
    "    if meta_temporal:\n",
    "        encoder_input_dim = 1 + len(metatemp_columns)\n",
    "        meta_temporal_dim = len(metatemp_columns)\n",
    "    else:\n",
    "        encoder_input_dim = 1\n",
    "        meta_temporal_dim = 0\n",
    "        \n",
    "    encoder = Encoder(input_dim= encoder_input_dim, enc_hid_dim=32, dec_hid_dim=32,\n",
    "                      num_layers=4, dropout=dropout\n",
    "                     ).to(device)\n",
    "    attention = Attention(enc_hid_dim=32, dec_hid_dim=32)\n",
    "    decoder = Decoder(input_dim=1, output_dim= 1, enc_hid_dim=32, dec_hid_dim=32, fc_dim=32,\n",
    "                      num_layers=4, dropout=dropout, attention=attention, bayesian=bayesian,\n",
    "                      embed_dim = None, meta_temporal_dim=meta_temporal_dim\n",
    "                     ).to(device)\n",
    "    net = Seq2Seq(encoder, decoder, device, N_output, mc_dropout=mc_dropout, embedder=embedder, use_meta_temporal=meta_temporal).to(device)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())  \n",
    "print(torch.cuda.is_available())   \n",
    "print(torch.version.cuda) \n",
    "nets_lists = {}\n",
    "#nets_lists['mse_ensembling'] = []\n",
    "nets_lists['meta_mc_dropout'] = []\n",
    "for i in range(5):\n",
    "    net = gen_net(dropout=0.5, bayesian=True, mc_dropout=True, meta_temporal=True)\n",
    "    train_model(net, loss_type=['fake_baye'], optimizer_parameters=optimizer_parameters,\n",
    "            epochs=100, eval_every=10)\n",
    "    nets_lists['meta_mc_dropout'].extend([net]*100)\n",
    "\n",
    "[x.log_rescale_factor for x in nets_lists['meta_mc_dropout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
