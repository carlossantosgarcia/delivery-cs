{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size='6' font-weight='bold'> BCG Gamma - Datathlon </font> </center>\n",
    "<center> <i> Matthias Lesage, Julien Pinède, Soukaina Lidam, Carlos Santos García, Timothé Chaumont et Tony Wu </i> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Imports-des-modules\" data-toc-modified-id=\"Imports-des-modules-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports des modules</a></span></li><li><span><a href=\"#Récupération-des-données\" data-toc-modified-id=\"Récupération-des-données-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Récupération des données</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# à remplir\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez vous référer au notebook `cleaning.ipynb` qui contient l'ensemble du code ayant permis de générer le module `cleaning.py`. Ce notebook détaille toutes les étapes nécessaires au pré-traitement des données et à l'ajout des features supplémentaires utiles à notre objectif.  \n",
    "  \n",
    "Voici un aperçu du notebook :  \n",
    "(insérer image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supposera les fichiers `.csv` préalablement téléchargées et placés dans le répertoire `data` à la racine du repository du projet.  \n",
    "\n",
    "(insérer capture d'écran)\n",
    "  \n",
    "  \n",
    "Si ce n'est pas le cas ou si vous voulez télécharger les dernières versions de ces fichiers, voici les liens pour récupérer les données utiles :  \n",
    "- **Comptages routiers :**\n",
    "  - https://opendata.paris.fr/explore/dataset/comptages-routiers-permanents/information/?disjunctive.libelle&disjunctive.etat_trafic&disjunctive.libelle_nd_amont&disjunctive.libelle_nd_aval&sort=t_1h\n",
    "\n",
    "- **Jours fériés :**\n",
    "  - https://www.data.gouv.fr/en/datasets/jours-feries-en-france/\n",
    "- **Vacances scolaires :**\n",
    "  - https://www.data.gouv.fr/en/datasets/le-calendrier-scolaire/\n",
    "- **Données météo :**\n",
    "  - https://www.worldweatheronline.com/developer/api/docs/historical-weather-api.aspx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les fichiers récupérés, on se prépare alors à lancer le module créé par nos soins.  \n",
    "Voici la docstring de la fonction qui nous sera utile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function export_datasets in module cleaning:\n",
      "\n",
      "export_datasets(sep_date_str, export=True)\n",
      "    Exports train and test sets in ./data folder as a pickle file. The data is in\n",
      "    chronological order and split using the given separation date.\n",
      "    Use pd.read_pickle to retrieve the data.\n",
      "    \n",
      "    Args:\n",
      "        sep_date_str (string): String with default format for pd.Timestamp function\n",
      "        export (bool): Set to False if you don't want to write data in files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(export_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il faut définir une date pour séparer le dataset en un trainset et un testset. Voici ci-dessous un widget pour sélectionner une date personalisée.  \n",
    "\n",
    "**Remarque :** Le calendrier est mis à la valeur qui nous a servi lors de nos expériences et tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750c77bc1f694687a3107d6ccbb0af41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.datetime(2020, 11, 10, 0, 0), description='Separation date')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Date de séparation pour le dataset utilisée lors de nos tests :\n",
    "default_sep_date = datetime.strptime('2020-11-10', '%Y-%m-%d')\n",
    "\n",
    "# On crée le DatePicker :\n",
    "widget_sep_date = widgets.DatePicker(\n",
    "        description='sep_date',\n",
    "        disabled=False,\n",
    "        value=default_sep_date\n",
    "    )\n",
    "\n",
    "# On récupère la 1ère valeur du DatePicker à l'initialisation :\n",
    "sep_date = widget_sep_date.value\n",
    "\n",
    "# Fonction auxiliaire qui sera appelée dès que la valeur du\n",
    "# DatePicker aura changé :\n",
    "def on_change(v):\n",
    "    global sep_date\n",
    "    sep_date = v['new']\n",
    "    return\n",
    "\n",
    "# Instanciation de l'observateur :\n",
    "widget_sep_date.observe(on_change, names='value')\n",
    "\n",
    "# Affichage du widget :\n",
    "display(widget_sep_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = export_datasets(sep_date_str=sep_date_str)\n",
    "\n",
    "print(f'len(df_train): {len(df_train)}\\nlen(df_test): {len(df_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
